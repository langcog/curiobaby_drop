---
title: "curiobaby_drop model analysis"
author: "George Kachergis"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
require(tidyverse)
require(here)
```

## Load data

```{r, load-data}
raw <- read.table(here("models/model_stats.csv"), sep=',')
cnames <- raw[1,]
mdat <- raw[2:nrow(raw),]
names(mdat) = cnames
for(c in 1:(ncol(mdat)-3)) {
  mdat[,c] = as.numeric(mdat[,c])
}
mdat$trial = rep(1:20, each=2)
# right now, each trial is 2 rows, 
# uniquely identified with drop_object x condition
#mdat %>% distinct(drop_object, condition)

mdat <- mdat %>% rename(drop = drop_object,
                        target = target_object,
                        relation = condition) %>%
  mutate(drop = replace(drop, drop=="triangular_prism", "trig prism"),
         target = replace(target, target=="triangular_prism", "trig prism"))

colMeans(mdat[,1:22])
# obj_final_position_invstd_objects=drop = -0.2980893  should that be negative?

# engineer some features: 
# combine target + drop target features
mdat_eng <- mdat %>%
  mutate(obj_final_position_std = 
           `obj_final_position_std_objects=drop` + 
           `obj_final_position_std_objects=target`,
         normed_velocity_std_after_first_collision_objects = 
           `normed_velocity_std_after_first_collision_objects=drop` + 
           `normed_velocity_std_after_first_collision_objects=target`,
         avg_final_radius_objects = 
           `avg_final_radius_objects=drop` + 
           `avg_final_radius_objects=target`,
         avg_max_radius_objects = 
           `avg_max_radius_objects=drop` + 
           `avg_max_radius_objects=target`,
         max_radius_std_objects = 
           `max_radius_std_objects=drop` + 
           `max_radius_std_objects=target`,
         support_combo = 
           support_probability + 
           support_std + 
           `support_response_sharpness_C=1e-05`, # add one of support_response_linearity_r or _pv ?
         len_combo = avg_len + len_std + len_inverse_sharpe_ratio
         ) %>%
  select(-`obj_final_position_std_objects=drop`, 
         -`obj_final_position_std_objects=target`,
         -`normed_velocity_std_after_first_collision_objects=drop`,
         -`normed_velocity_std_after_first_collision_objects=target`,
         -`avg_final_radius_objects=drop`,
         -`avg_final_radius_objects=target`,
         -`avg_max_radius_objects=drop`,
         -`avg_max_radius_objects=target`,
         -`max_radius_std_objects=drop`,
         -`max_radius_std_objects=target`,
         -support_probability, 
         -support_std,
         -`support_response_sharpness_C=1`,
         -`support_response_sharpness_C=1e-05`,
         -`support_response_sharpness_C=100000.0`,
         -avg_len, -len_inverse_sharpe_ratio, -len_std,
         -support_response_linearity_pv, -support_response_linearity_r,
         -`obj_final_position_invstd_objects=target`,
         -`obj_final_position_invstd_objects=drop`
         )



# selects given feature and returns wide df that can be compared with behavioral data
get_feature_df <- function(mdat, fname) {
  fdf <- mdat[,c(fname,"drop","target","relation")] %>%
    pivot_wider(id_cols = c("drop","relation"), names_from = "target", values_from = fname) %>%
    arrange(relation,drop)
}

```

# Fit to adult choice proportions

```{r}
load(file=here("paper/processed_data.RData")) 

# ToDo: hold out half the subjects and CV on other half
adult_trial_agg <- adult_long %>% group_by(relation, drop, target) %>% # alt, 
  summarize(chose_target=mean(chose_target, na.rm=T)) %>% # , n=n()
  arrange(relation, desc(chose_target))

#hum_ad <- adult_trial_agg %>%
#  pivot_wider(id_cols = c("drop","relation"), names_from = "target", values_from = chose_target) %>%
#  arrange(relation,drop)

softmax <- function(weights, beta=1, smooth=1e-7) {
  weights = weights + smooth
  probs = (weights / sum(weights)) # normalize first
  num <- exp(beta * probs)
  return(num / sum(num))
}


get_model_target_choice_props <- function(feat_df, hum_df, beta) {
  hum_df <- hum_df %>% arrange(relation, drop) # same order as model df
  hum_df$Model_targ_prop = 0
  for(i in 1:nrow(hum_df)) {
    mod_cols = which(!is.na(feat_df[i,1:ncol(feat_df)]))[3:4]
    mod_choice = softmax(feat_df[i,mod_cols], beta=beta)
    hum_df[i,]$Model_targ_prop = as.numeric(mod_choice[hum_df[i,]$target] / sum(mod_choice))
  }
  return(hum_df)
}

evalFit <- function(feat_df, hum_df, beta) {
  hum_df <- get_model_target_choice_props(feat_df, hum_df, beta)
  #r = with(hum_df, cor(chose_target, Model_targ_prop))
  mse = with(hum_df, sum((chose_target - Model_targ_prop)^2)) / nrow(hum_df)
  return(mse) # return negative cor since DEoptim minimizes
}

require(DEoptim)

feat_names = names(mdat)[1:(ncol(mdat)-4)]
# for each feature, want to fit beta to maximize correlation between human and model choices
#feat_df <- get_feature_df(mdat, feat_names[1])

adult_fits = list()
for(feat in feat_names) {
  feat_df <- get_feature_df(mdat, feat)
  #paste(feat, evalFit(feat_df, adult_trial_agg, 1))
  adult_fits[[feat]] = DEoptim(evalFit, lower=.7, upper=5, DEoptim.control(reltol=.001, NP=30, itermax=70), 
                feat_df=feat_df, hum_df=adult_trial_agg)
}
```



# Compare to children's choices

```{r}
child_trial_agg <- child_long %>% group_by(relation, drop, target) %>% # alt, 
  summarize(chose_target=mean(chose_target, na.rm=T), n=n())

child_fits = list()
for(feat in feat_names) {
  feat_df <- get_feature_df(mdat, feat)
  child_fits[[feat]] = DEoptim(evalFit, lower=.7, upper=5, DEoptim.control(reltol=.001, NP=30, itermax=70), 
                feat_df=feat_df, hum_df=child_trial_agg)
}
```

## Now try engineered features

```{r adult-eng-feats}
feat_names2 = names(mdat_eng)[5:ncol(mdat_eng)]

for(feat in feat_names2) {
  feat_df <- get_feature_df(mdat_eng, feat)
  #paste(feat, evalFit(feat_df, adult_trial_agg, 1))
  adult_fits[[feat]] = DEoptim(evalFit, lower=.7, upper=5, DEoptim.control(reltol=.001, NP=30, itermax=70), 
                feat_df=feat_df, hum_df=adult_trial_agg)
  child_fits[[feat]] = DEoptim(evalFit, lower=.7, upper=5, DEoptim.control(reltol=.001, NP=30, itermax=70), 
                feat_df=feat_df, hum_df=child_trial_agg)
}

```



```{r}
adult_mfit <- tibble()
child_mfit <- tibble()

for(f in names(adult_fits)) {
  adult_mfit = bind_rows(adult_mfit, c(feature=f, 
                                       beta=as.numeric(unlist(adult_fits[[f]]$optim$bestmem)), 
                                       mse=adult_fits[[f]]$optim$bestval))
  child_mfit = bind_rows(child_mfit, c(feature=f, 
                                       beta=as.numeric(unlist(child_fits[[f]]$optim$bestmem)), 
                                       mse=child_fits[[f]]$optim$bestval))
}

adult_mfit <- adult_mfit %>% 
  mutate(beta = as.numeric(beta),
         mse = as.numeric(mse)) %>%
  arrange(mse)

```

```{r children}
child_mfit <- child_mfit %>% 
  mutate(beta = as.numeric(beta),
         mse = as.numeric(mse)) %>%
  arrange(mse)

fit_tab <- child_mfit %>% rename(child_mse = mse, child_beta = beta) %>%
  left_join(adult_mfit %>% rename(adult_mse = mse, adult_beta = beta)) %>% 
  arrange(adult_mse)

knitr::kable(fit_tab, digits = 3)
```



```{r}
fits <- child_mfit %>% mutate(AgeGroup = "children") %>% 
  bind_rows(adult_mfit %>% mutate(AgeGroup = "adults"))

save(mdat, mdat_eng, fits, file=here("models/model_data.RData"))
```

```{r, eval=F}
fits %>% ggplot(aes(x=beta, y=mse, color=AgeGroup)) +
  #geom_text(aes(label=feature)) + 
  geom_point(alpha=.5) +
  theme_minimal()
```
So generally, children's choices are best explained by small values of beta (.5, the minimum tested).


What do the predicted choice proportions from the best feature for each age group look like?

```{r}
require(ggpubr)

plot_model_preds <- function(feat_name, fits, hum_data, age="adults", mdat) {
  beta = 1 #subset(fits, AgeGroup==age & feature==feat_name)$beta
  md <- get_model_target_choice_props(get_feature_df(mdat, feat_name), hum_data, beta)
  md %>% ggplot(aes(x=chose_target, y=Model_targ_prop, color=relation)) +
    geom_abline(slope=1, intercept=0, linetype="dashed") +
    geom_point(alpha=.5) + geom_smooth(method='lm') + 
    xlab("Human Choice Probability") + 
    ylab("Model Choice Probability") +
    ggtitle(paste0(feat_name,": ",age)) + theme_minimal() + 
    xlim(0,1) + ylim(0,1)
}

ad_supp <- plot_model_preds("support_probability", fits, adult_trial_agg, age="adults", mdat)
ch_supp <- plot_model_preds("support_probability", fits, child_trial_agg, age="children", mdat)

ggarrange(ad_supp, ch_supp, nrow=1, common.legend = T)
```


```{r}
ad <- plot_model_preds("support_combo", fits, adult_trial_agg, age="adults", mdat_eng)
ch <- plot_model_preds("support_combo", fits, child_trial_agg, age="children", mdat_eng)

ggarrange(ad, ch, nrow=1, common.legend = T)
```

```{r}
ad <- plot_model_preds("support_response_sharpness_C=1e-05", fits, adult_trial_agg, age="adults", mdat)
ch <- plot_model_preds("support_response_sharpness_C=1e-05", fits, child_trial_agg, age="children", mdat)

ggarrange(ad, ch, nrow=1, common.legend = T)
```

```{r}
ad <- plot_model_preds("support_std", fits, adult_trial_agg, age="adults", mdat)
ch <- plot_model_preds("support_std", fits, child_trial_agg, age="children", mdat)

ggarrange(ad, ch, nrow=1, common.legend = T)
```

```{r}
ad <- plot_model_preds("len_inverse_sharpe_ratio", fits, adult_trial_agg, age="adults", mdat)
ch <- plot_model_preds("len_inverse_sharpe_ratio", fits, child_trial_agg, age="children", mdat)

ggarrange(ad, ch, nrow=1, common.legend = T)
```


```{r}
ad <- plot_model_preds("avg_final_radius_objects=target", fits, adult_trial_agg, age="adults", mdat)
ch <- plot_model_preds("avg_final_radius_objects=target", fits, child_trial_agg, age="children", mdat)

ggarrange(ad, ch, nrow=1, common.legend = T)
```
