---
title: "curiobaby_drop model analysis"
author: "George Kachergis"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
require(tidyverse)
require(here)

FIT_MODELS = F
```

## Preprocessing

```{r, load-data, echo=F, FIT_MODELS=F}

load_data <- function(fname) {
  raw <- read.table(here(paste0("models/",fname,".csv")), sep=',')
  cnames <- raw[1,]
  mdat <- raw[2:nrow(raw),]
  names(mdat) = cnames
  for(c in 1:(ncol(mdat)-3)) {
    mdat[,c] = as.numeric(mdat[,c])
    if(min(mdat[,c]) < 0) mdat[,c] = mdat[,c] + min(mdat[,c])
    print(paste("shifting",c,"so minimum is 0"))
  }
  mdat$trial = rep(1:20, each=2)
  # right now, each trial is 2 rows, 
  # uniquely identified with drop_object x condition
  #mdat %>% distinct(drop_object, condition)

  mdat <- mdat %>% rename(drop = drop_object,
                          target = target_object,
                          relation = condition) %>%
    mutate(drop = replace(drop, drop=="triangular_prism", "trig prism"),
         target = replace(target, target=="triangular_prism", "trig prism"))
  return(mdat)
}

# just 100 drops per trial
mdat100 <- load_data("model_stats")

mdat <- load_data("model_stats250")

sort(colMeans(mdat[,1:43]))
# mean of obj_final_position_invstd_objects=drop is negative..
# mean of avg_len is 235, and len_std is 45 (much larger than typical feature mean on order of .1 - 1.0)
# scale these cols? (only matters for their combination)
mdat$avg_len = mdat$avg_len / max(mdat$avg_len)
mdat$len_std = mdat$len_std / max(mdat$len_std)

# engineer some features: 
# combine target + drop target features
mdat_eng <- mdat %>%
  rowwise() %>%
  mutate(obj_final_position_std = mean(`obj_final_position_std_objects=drop`,
                                       `obj_final_position_std_objects=target`),
         normed_velocity_std_after_first_collision_objects = 
           mean(`normed_velocity_std_after_first_collision_objects=drop`,
                `normed_velocity_std_after_first_collision_objects=target`),
         avg_final_radius_objects = mean(`avg_final_radius_objects=drop`, 
                                         `avg_final_radius_objects=target`),
         avg_max_radius_objects = mean(`avg_max_radius_objects=drop`,
                                       `avg_max_radius_objects=target`),
         max_radius_std_objects = mean(`max_radius_std_objects=drop`,
                                       `max_radius_std_objects=target`),
         support_combo = mean(support_probability, support_std, 
                              `support_response_sharpness_C=1`, # add support_response_linearity_r or _pv ?
                              `support_response_sharpness_accuracy_C=1`),
         support_sharpness_mean = mean(`support_response_sharpness_C=1e-05`,
                                       `support_response_sharpness_C=0.0001`,
                                       `support_response_sharpness_C=0.001`,
                                       `support_response_sharpness_C=0.01`,
                                       `support_response_sharpness_C=0.1`,
                                       `support_response_sharpness_C=1`,
                                       `support_response_sharpness_C=10.0`,
                                       `support_response_sharpness_C=100.0`,
                                       `support_response_sharpness_C=1000.0`,
                                       `support_response_sharpness_C=10000.0`,
                                       `support_response_sharpness_C=100000.0`),
         support_sharpness_accuracy_mean = mean(
            `support_response_sharpness_accuracy_C=1e-05`,
             `support_response_sharpness_accuracy_C=0.0001`,
             `support_response_sharpness_accuracy_C=0.001`,
             `support_response_sharpness_accuracy_C=0.01`,
             `support_response_sharpness_accuracy_C=0.1`,
             `support_response_sharpness_accuracy_C=1`,
             `support_response_sharpness_accuracy_C=10.0`,
             `support_response_sharpness_accuracy_C=100.0`,
             `support_response_sharpness_accuracy_C=1000.0`,
             `support_response_sharpness_accuracy_C=10000.0`,
             `support_response_sharpness_accuracy_C=100000.0`),
         support_response_linearity_mean = mean(support_response_linearity_pv, 
                                                support_response_linearity_r),
         len_combo = mean(avg_len, len_std, len_inverse_sharpe_ratio)
         ) %>%
  select(obj_final_position_std, 
         normed_velocity_std_after_first_collision_objects, 
         avg_final_radius_objects,
         avg_max_radius_objects,
         max_radius_std_objects,
         support_combo, 
         support_sharpness_mean,
         support_sharpness_accuracy_mean,
         len_combo,
         drop, target, relation)

mdat <- mdat %>% left_join(mdat_eng)
```

# Load human data

Define helper functions

```{r, echo=F}
# selects given feature and returns wide df that can be compared with behavioral data
get_feature_df <- function(mdat, fname) {
  fdf <- mdat[,c(fname,"drop","target","relation")] %>%
    pivot_wider(id_cols = c("drop","relation"), names_from = "target", values_from = fname) %>%
    arrange(relation,drop)
}

load(file=here("paper/processed_data.RData")) 

# ToDo: hold out half the subjects and CV on other half
adult_trial_agg <- adult_long %>% group_by(relation, drop, target) %>% # alt, 
  summarize(chose_target=mean(chose_target, na.rm=T)) %>% # , n=n()
  arrange(relation, desc(chose_target))

#hum_ad <- adult_trial_agg %>%
#  pivot_wider(id_cols = c("drop","relation"), names_from = "target", values_from = chose_target) %>%
#  arrange(relation,drop)

softmax <- function(weights, beta=1, smooth=1e-7) {
  weights = weights + smooth
  probs = (weights / sum(weights)) # normalize first
  num <- exp(beta * probs)
  return(num / sum(num))
}
# softmax(c(.7,.3), beta=2)

get_model_target_choice_props <- function(feat_df, hum_df, beta) {
  hum_df <- hum_df %>% arrange(relation, drop) # same order as model df
  hum_df$Model_targ_prop = 0
  for(i in 1:nrow(hum_df)) {
    mod_cols = which(!is.na(feat_df[i,1:ncol(feat_df)]))[3:4] # CHECK THIS
    mod_choice = softmax(feat_df[i,mod_cols], beta=beta)
    hum_df[i,]$Model_targ_prop = as.numeric(mod_choice[hum_df[i,]$target] / sum(mod_choice))
  }
  return(hum_df)
}


evalFit <- function(feat_df, hum_df, beta, cor_objective=F, relation=NA) {
  hum_df <- get_model_target_choice_props(feat_df, hum_df, beta)
  if(!is.na(relation)) {
    hum_df <- hum_df[which(hum_df$relation==relation),]
  }
  r = with(hum_df, cor(chose_target, Model_targ_prop))
  mse = with(hum_df, sum((chose_target - Model_targ_prop)^2)) / nrow(hum_df) 
  if(cor_objective) mse = mse - r # also try to minimize -correlation
  return(mse) # return negative cor since DEoptim minimizes
}

feat_names = setdiff(names(mdat), c("drop","target","relation","trial"))
# for each feature, want to fit beta to maximize correlation between human and model choices
#feat_df <- get_feature_df(mdat, feat_names[1])

child_trial_agg <- child_long %>% group_by(relation, drop, target) %>% # alt, 
  summarize(chose_target=mean(chose_target, na.rm=T), n=n())
```


## Fit models to all trials (MSE objective)

Find best-fitting betas per feature for children and adults, contain and support trials together.

```{r fit-models-to-all-trials-mse, echo=F, eval=FIT_MODELS}
require(DEoptim)

all_trials_mse <- tibble()

for(feat in feat_names) {
  feat_df <- get_feature_df(mdat, feat)
  #paste(feat, evalFit(feat_df, adult_trial_agg, 1))
  adult_fit = DEoptim(evalFit, lower=.5, upper=10, DEoptim.control(reltol=.001, NP=30, itermax=20), 
                feat_df=feat_df, hum_df=adult_trial_agg)
  child_fit = DEoptim(evalFit, lower=.5, upper=10, DEoptim.control(reltol=.001, NP=30, itermax=20), 
                feat_df=feat_df, hum_df=child_trial_agg)
  all_trials_mse <- bind_rows(all_trials_mse, c(Age = "adults", feature=feat, beta=as.numeric(unlist(adult_fit$optim$bestmem)), 
                          mse = adult_fit$optim$bestval))
  all_trials_mse <- bind_rows(all_trials_mse, c(Age = "children", feature=feat, 
                          beta = as.numeric(unlist(child_fit$optim$bestmem)), 
                          mse = child_fit$optim$bestval))
}

all_trials_mse_r <- all_trials_mse_r %>% mutate(beta = as.numeric(beta),
                                                mse = as.numeric(mse))

save(all_trials_mse, file=here("models/all_trials_mse.RData"))
```

## Fit models to all trials (MSE + r objective)


```{r fit-models-to-all-trials-mse-and-r, echo=F, eval=FIT_MODELS}
all_trials_mse_r <- tibble()

for(feat in feat_names) {
  feat_df <- get_feature_df(mdat, feat)
  #paste(feat, evalFit(feat_df, adult_trial_agg, 1))
  adult_fit = DEoptim(evalFit, lower=.5, upper=10, DEoptim.control(reltol=.001, NP=30, itermax=20), 
                feat_df=feat_df, hum_df=adult_trial_agg, cor_objective=T)
  child_fit = DEoptim(evalFit, lower=.5, upper=10, DEoptim.control(reltol=.001, NP=30, itermax=20), 
                feat_df=feat_df, hum_df=child_trial_agg, cor_objective=T)
  all_trials_mse_r <- bind_rows(all_trials_mse_r, c(Age = "adults", feature=feat, beta=as.numeric(unlist(adult_fit$optim$bestmem)), 
                          mse = adult_fit$optim$bestval))
  all_trials_mse_r <- bind_rows(all_trials_mse_r, c(Age = "children", feature=feat, 
                          beta = as.numeric(unlist(child_fit$optim$bestmem)), 
                          mse = child_fit$optim$bestval))
}

all_trials_mse_r <- all_trials_mse_r %>% mutate(beta = as.numeric(beta),
                                                mse = as.numeric(mse))

```

## Fit separately to contain and support trials (MSE)

```{r fit-models-to-supp-cont-trials-mse, echo=F, eval=FIT_MODELS}
supp_trials_mse <- tibble()
cont_trials_mse <- tibble()

for(feat in feat_names) {
  feat_df <- get_feature_df(mdat, feat)
  #paste(feat, evalFit(feat_df, adult_trial_agg, 1))
  adult_fit = DEoptim(evalFit, lower=.5, upper=10, DEoptim.control(reltol=.001, NP=30, itermax=20), 
                feat_df=feat_df, hum_df=adult_trial_agg, relation="support")
  child_fit = DEoptim(evalFit, lower=.5, upper=10, DEoptim.control(reltol=.001, NP=30, itermax=20), 
                feat_df=feat_df, hum_df=child_trial_agg, relation="support")
  supp_trials_mse <- bind_rows(supp_trials_mse, c(Age = "adults", feature=feat, beta=as.numeric(unlist(adult_fit$optim$bestmem)), 
                          mse = adult_fit$optim$bestval))
  supp_trials_mse <- bind_rows(supp_trials_mse, c(Age = "children", feature=feat, 
                          beta = as.numeric(unlist(child_fit$optim$bestmem)), 
                          mse = child_fit$optim$bestval))
}

supp_trials_mse <- supp_trials_mse %>% mutate(beta = as.numeric(beta),
                                                mse = as.numeric(mse))


for(feat in feat_names) {
  feat_df <- get_feature_df(mdat, feat)
  adult_fit = DEoptim(evalFit, lower=.5, upper=10, DEoptim.control(reltol=.001, NP=30, itermax=20), 
                feat_df=feat_df, hum_df=adult_trial_agg, relation="contain")
  child_fit = DEoptim(evalFit, lower=.5, upper=10, DEoptim.control(reltol=.001, NP=30, itermax=20), 
                feat_df=feat_df, hum_df=child_trial_agg, relation="contain")
  cont_trials_mse <- bind_rows(cont_trials_mse, c(Age = "adults", feature=feat, beta=as.numeric(unlist(adult_fit$optim$bestmem)), 
                          mse = adult_fit$optim$bestval))
  cont_trials_mse <- bind_rows(cont_trials_mse, c(Age = "children", feature=feat, 
                          beta = as.numeric(unlist(child_fit$optim$bestmem)), 
                          mse = child_fit$optim$bestval))
}

cont_trials_mse <- cont_trials_mse %>% mutate(beta = as.numeric(beta),
                                                mse = as.numeric(mse))

save(mdat, all_trials_mse, all_trials_mse_r, 
     supp_trials_mse, cont_trials_mse, file=here("models/model_data.RData"))
```


Could also fit separately to contain and support trials with MSE - r objective...


```{r}
load(here("models/model_data.RData"))
```


## Fits to all trials

```{r, echo=F}
fit_tab <- all_trials_mse %>% pivot_wider( names_from = Age, values_from = c(beta, mse)) %>%
  arrange(mse_adults)

knitr::kable(fit_tab, digits = 3)
```


## Fits to all trials (MSE - r)

```{r, echo=F}
all_trials_mse_r <- all_trials_mse_r %>% mutate(beta = as.numeric(beta),
                                                mse = as.numeric(mse))

fit_tab <- all_trials_mse_r %>% pivot_wider( names_from = Age, values_from = c(beta, mse)) %>%
  arrange(mse_adults)

knitr::kable(fit_tab, digits = 3)
```


## Fits to support trials (MSE)

```{r, echo=F}
fit_tab <- supp_trials_mse %>% pivot_wider(names_from = Age, values_from = c(beta, mse)) %>%
  arrange(mse_adults)

knitr::kable(fit_tab, digits = 3)
```

## Fits to containment trials (MSE)

```{r, echo=F}
fit_tab <- cont_trials_mse %>% pivot_wider(names_from = Age, values_from = c(beta, mse)) %>%
  arrange(mse_adults)

knitr::kable(fit_tab, digits = 3)
```


What do the predicted choice proportions from the best features for each age group look like?
Let's look at the best feature for each each group from each fit method.

```{r, echo=F, message=F}
require(ggpubr)

plot_model_preds <- function(feat_name, fits, hum_data, age="adults", mdat) {
  this_dat = subset(fits, Age==age & feature==feat_name)
  md <- get_model_target_choice_props(get_feature_df(mdat, feat_name), hum_data, beta)
  md %>% ggplot(aes(x=chose_target, y=Model_targ_prop, color=relation)) +
    geom_abline(slope=1, intercept=0, linetype="dashed") +
    geom_point(alpha=.5) + geom_smooth(method='lm', formula=y ~ x) + 
    xlab("Human Choice Probability") + 
    ylab("Model Choice Probability") +
    ggtitle(paste0(feat_name,": ",age)) + theme_minimal() + 
    xlim(0,1) + ylim(0,1) +
    annotate("text", x=.5, y=0.05, 
             label = paste0("beta = ",round(this_dat$beta,2),", MSE = ",round(this_dat$mse, 3))) # 
}
```



## Plots of other best-fitting features for all trials (MSE fits)

```{r, echo=F, message=F}
ad_supp <- plot_model_preds("support_probability", all_trials_mse, adult_trial_agg, age="adults", mdat)
ch_supp <- plot_model_preds("support_probability", all_trials_mse, child_trial_agg, age="children", mdat)

ggarrange(ad_supp, ch_supp, nrow=1, common.legend = T)
```


```{r,  echo=F, message=F}
ad <- plot_model_preds("support_combo", all_trials_mse, adult_trial_agg, age="adults", mdat)
ch <- plot_model_preds("support_combo", all_trials_mse, child_trial_agg, age="children", mdat)

ggarrange(ad, ch, nrow=1, common.legend = T)
```

```{r, echo=F, message=F}
ad <- plot_model_preds("support_std", all_trials_mse, adult_trial_agg, age="adults", mdat)
ch <- plot_model_preds("support_std", all_trials_mse, child_trial_agg, age="children", mdat)

ggarrange(ad, ch, nrow=1, common.legend = T)
```

```{r,  echo=F, message=F}
ad <- plot_model_preds("support_response_sharpness_C=0.01", all_trials_mse, adult_trial_agg, age="adults", mdat)
ch <- plot_model_preds("support_response_sharpness_C=0.01", all_trials_mse, child_trial_agg, age="children", mdat)

ggarrange(ad, ch, nrow=1, common.legend = T)
```

```{r,  echo=F, message=F}
ad <- plot_model_preds("len_inverse_sharpe_ratio", all_trials_mse, adult_trial_agg, age="adults", mdat)
ch <- plot_model_preds("len_inverse_sharpe_ratio", all_trials_mse, child_trial_agg, age="children", mdat)

ggarrange(ad, ch, nrow=1, common.legend = T)
```


```{r,  echo=F, message=F}
ad <- plot_model_preds("avg_final_radius_objects=target", all_trials_mse, adult_trial_agg, age="adults", mdat)
ch <- plot_model_preds("avg_final_radius_objects=target", all_trials_mse, child_trial_agg, age="children", mdat)

ggarrange(ad, ch, nrow=1, common.legend = T)
```

```{r,  echo=F, message=F}
ad <- plot_model_preds("support_response_linearity_r", all_trials_mse, adult_trial_agg, age="adults", mdat)
ch <- plot_model_preds("support_response_linearity_r", all_trials_mse, child_trial_agg, age="children", mdat)

ggarrange(ad, ch, nrow=1, common.legend = T)
```

```{r,  echo=F, message=F}
ad <- plot_model_preds("support_sharpness_mean", all_trials_mse, adult_trial_agg, age="adults", mdat)
ch <- plot_model_preds("support_sharpness_mean", all_trials_mse, child_trial_agg, age="children", mdat)

ggarrange(ad, ch, nrow=1, common.legend = T)
```
