---
#title: "Modeling children's intrinsically-motivated curiosity about object interactions"
#title: "Drop it like it's hot: Modeling children's curiosity about physical interactions"
#title: "A drop in the bucket: Progress towards modeling children's curiosity about physical interactions"
title: "What if you drop that? Modeling children's curiosity about physical interactions"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Morton Ann Gernsbacher (MAG@Macc.Wisc.Edu)} \\ Department of Psychology, 1202 W. Johnson Street \\ Madison, WI 53706 USA
    \AND {\large \bf Sharon J.~Derry (SDJ@Macc.Wisc.Edu)} \\ Department of Educational Psychology, 1025 W. Johnson Street \\ Madison, WI 53706 USA}

abstract: >
     Curiosity is a fundamental driver of human behavior, and yet because of its open-ended nature 
     and the wide variety of behaviors it inspires in different contexts, it is remarkably difficult 
     to study in a laboratory context. A promising approach to developing and testing theories of 
     curiosity is to instantiate them in artificial agents that are able to act and explore in a 
     simulated environment, and then compare the behavior of these agents to humans exploring the 
     same stimuli. Here we propose a new paradigm for examining curiosity about physical interact
    
keywords: >
    curiosity; novel objects; object interactions; intuitive physics
    
output: cogsci2016::cogsci_paper
#    includes:
#      in_header: preamble.tex
#final-submission: \cogscifinalcopy
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(ggplot2)
library(xtable)
require(here)
require(tidyverse)
require(tidyboot)
```

```{r, load-data}
raw = read.csv2("../analysis/human-data/curiobaby_drop-data - drop exp.csv", sep=',', header=T, stringsAsFactors=F)
hum = subset(raw, Exclude!="Y")

hum = hum[-which(hum$StimSet=="bc" & hum$DropChoice=="bowl and dumbbell"),] # chose two - exclude

s_tr <- hum %>% group_by(SID, Age_Group) %>% summarise(max=max(Trial)) %>% arrange(max)
age = table(s_tr$Age_Group)
```

# Introduction 

Curiosity is a fundamental part of our motivation, driving everyday behaviors that we spend a surprising amount of time pursuing, from browsing the internet to reading novels, watching the news, and many other forms of information seeking.
Curiosity is so strongly linked to learning that William James (1899) considered it to be "the impulse towards better cognition", a description that is echoed in Piaget's [-@Piaget1952] theory of development, which holds that children actively construct their knowledge through physical exploration of the world.
Taking this view of children [even infants: @Gopnik2009] as "little scientists", researchers have credited curiosity for inspiring behaviors ranging from novelty-seeking to exploration and play, and yet there is a major outstanding difficulty in curiosity research: there is no integrative theory of the mechanisms and basis for curiosity [@Kidd2015].
What combinations of stimuli and knowledge states inspire curiosity? 
By what mechanism does curiosity motivate and drive action selection, and influence subsequent learning and behavior?

Although several theories of curiosity (surveyed briefly below) partially address these issues, a gold standard for testing these theories would require a fully-instantiated theory of curiosity in an artificial agent whose behavior can be directly compared to that of humans.
However, a further difficulty of this approach is selecting a task that adequately captures the general nature of curiosity: curiosity-driven human behavior is so wide-ranging that it is difficult to systematically compare to presently limited artificial agents.
Behavioral investigations of children's exploratory play have often offered a single complex toy with a number of functions that can be discovered [e.g., @Cook2011; @Bonawitz2012; @Gweon2014], but the real world offers many more degrees of freedom.
The places where curiosity is most manifest tend to be those open-ended environments that are hardest to model -- an inviting playground, a surprisingly complex device, or a novel research question. 
In this paper we propose a new paradigm that allows us to directly compare children's curiosity about physical interactions with that of an aritifical agent implementing different functional forms of curiosity.
Below, we give a brief overview of theories of curiosity, relevant developmental empirical findings, and computational models instantiating curiosity.

## Theories of Curiosity

@Berlyne1954's influential theory of curiosity distinguished between perceptual curiosity, a desire to seek out novel stimuli (that decreases with familiarity), and epistemic curiosity, a desire to acquire knowledge. 
Berlyne additionally distinguished specific versus diversive curiosity, where the former is a drive for a particular piece of information, and the latter is a general motivation for stimulation.
More recent views of curiosity further limit the definition to information-seeking that is intrinsically-motivated, not linked to any obvious external reward [@Loewenstein1994; @Oudeyer2007].
However, it is often difficult for observers to determine whether any given decision is intrinsically- or extrinsically-motivated.
Modern theories also hold that the function of curiosity is inspired by awareness of a knowledge gap, and functions to drive behaviors that will result in learning [@Loewenstein1994].
Similar to other drives (e.g., hunger), curiosity is sated as relevant information is gained and the knowledge gap is closed.
Although these theories give us some sense of which situations and knowledge states should engender curiosity, both the mechanism and how actions are selected 

## Related Behavioral Work

Although the question of what inspires a child's curiosity is difficult to determine, it's generally agreed that curiosity indicates awareness of a knowledge gap that the learner is interested in filling [@Loewenstein1994].
Even young infants exhibit a preference to attend to novel stimuli over more familiar stimuli [e.g., @Fantz1964], and when surprising events do occur it has been shown to stimulate infants' exploration and subsequent learning [@Stahl2015].
Moreover, infants are sensitive to the level of complexity of stimuli, preferring to attend to those of intermediate complexity (rather than simple or overly-complex)--a bias which may help them optimize their information gain [@Kidd2012; @Kidd2014].
As theorized [@Piaget1952], exploratory play has been shown to be an opportunity for young children to learn [e.g., generalization: @Sim2017, causal structure: @Schulz2007; @Gweon2014].

One rich domain that young children are in the midst of learning about is the properties and affordances of physical objects.


## Computational Models of Curiosity

[Sentence on other approaches: @Oudeyer2013; @Schmidhuber2010]

Building on prior work that showed deep neural networks are capable of learning forward and inverse physical dynamics (i.e., "intuitive physics") from images when given the ability to "poke" the objects in the scene [@Agrawal2016], we use and extend a framework for constructing intrinsically-motivated artificial agents introduced in @Haber2018learning, described in the following. 

Model description here?

(maybe make the below a joint "Paradigm" section, then human behavior, model behavior and comparison)

# Experiment

## Method

### Participants
Participants were `r length(unique(raw$SID))` children recruited from the Children's Discovery Museum of San Jose and Bing Nursery School.
Participant exclusions were made based on cases where i) the participant did not complete more than half of the study play session or ii) the parent did not consent for video recording of study. 
After exclusions, results from `r length(unique(hum$SID))` were analyzed, including `r age[1]` 2-year-olds, `r age[2]` 3-year-olds, `r age[3]` 4-year-olds, `r age[4]` 5-year-olds, and `r age[5]` 6-year-olds. 

### Materials

```{r object-sets}
shapes = c("bowl","cone","dumbbell","octahedron","pentagon","pipe","pyramid","torus","trig prism")

a = c("pyramid", "torus", "trig prism")
b = c("cone", "octahedron", "pipe")
c = c("bowl", "dumbbell", "pentagon")
```

Stimuli were 3D-printed plastic objects produced using Blender 3D-modeling software. 
The nine objects, depicted in Figure 1, were bowl, cone, dumbbell, octahedron, pentagon (pentagonal prism), pipe, pyramid, torus, and triangular prism.
The printed objects were all yellow, rigid plastic material and designed to fit comfortably in the childâ€™s hand (dimension range: 3.8-10.1 cm). 

The set of 9 objects were divided into 3 subsets (A = {pyramid, torus, triangular prism}, B = {cone, octahedron, pipe}, and C = {bowl, dumbbell, pentagon}). 
These subsets served as sets (A, B, C) of target or drop objects in six successive blocks of 2 trials, making a total of 12 trials per participant.
For example, in Order 1, in the first block of 2 trials, set A served as the target objects from which the child chose to drop on the target objects (set B).
The target:drop block sequence for Order 1 was A:B, B:C, C:A, A:C, B:A, C:B. The sequence for Order 2 was the reverse of Order 1: C:B, B:A, A:C, C:A, B:C, A:B. Participants were assigned to condition in counterbalanced order.

Target objects were placed in a circular bin (25 in diameter x 10 in height). 
The bin was divided with tape into sections of equal area, and one target object from the appropriate set was placed in the center of each third. 
Drop objects were presented to participants on a table at approximately eye level.

```{r fig1-sets, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3, fig.height=3, set.cap.width=T, num.cols.cap=1, fig.cap = "Sets of 3D objects used for dropping and as targets."}
img <- png::readPNG("figs/drop_sets.png")
grid::grid.raster(img)
```

### Procedure

After the parent provided informed consent, children were assigned to Order 1 or Order 2. Participants were assigned to condition in counterbalanced order.
We introduced children to a set of 3D-printed toy objects ("blocks"). 
The child played a game where they could pick which of three blocks to drop in a bin containing three other blocks, to see what happens. 
An example trial is illustrated in Figure 2.
We then swapped target/drop blocks, based on assigned order sequence, and asked the child to do the same selection and dropping a dozen times. 
Finally, we asked the child to build a "cool" tower with any of the toy blocks for about one minute.

Based on piloting, we estimated the activity would would only require five minutes to complete. 
In both conditions, a video camera was used to record the play session from an angle above the bin, to show child's block selection and drop location as well as child's completed tower. 
After child notified the researcher that they were finished building their tower, the session was completed and camera was turned off. 

```{r fig2-task, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3, fig.height=2.5, set.cap.width=T, num.cols.cap=1, fig.cap = "Example trial."}
img <- png::readPNG("figs/DropTaskFigure.png")
grid::grid.raster(img)
```

### Drop Coding Procedure

Each session's video was manually coded for object drop choice and drop location. Drop choice is defined as the child's single selection of three drop objects to drop into the bin containing three different objects. 
The bin is divided into three sections of equal area. 
Each target object resides in one of these three areas. 
Drop location was defined as the site of collision of drop object at the base of the bin. 
Drop locations include either i) direct collision with one of three target objects, ii) collision in an empty space surrounding select target object, or iii) outside the bin. 

If the dropped object collided with empty space, we recorded the target object it landed closest to. 
We also recorded events where the dropped object bounced from empty space or a target object then collided with other target object(s). 
Number of collisions and with which target(s) was also coded.

Trials were excluded if child i) dropped object outside of the bin, ii) touched target object(s) prior to a drop, iii) dropped object during set change, iv) selected more than one object to drop, or iv) dropped (or threw) object from too high (>1.5 m). 
Trials were also excluded if the experimenter made a mistake (e.g., used the wrong stimulus set or repeated a trial more than twice).


## Results

```{r chance-comparison}

report_chisq <- function(X) {
  # e.g. X^2 (2, N = 88) = 2.1, p = .35
  pval = round(X$p.value, 3)
  if(pval==0) { 
    pval = ", p<.001" 
  } else {
    pval = paste0(", p=",pval)
  }
  return(paste0("($X^2$(", X$parameter, ", N=", sum(X$expected), ") = ", round(X$statistic,2), pval, ")"))
}

# see if children's choices (per subset) are random
drop_ch = table(hum$StimSet, hum$DropChoice)
# chisq.test(rbind(colSums(drop_ch[,a]), rep(sum(drop_ch[,a]/3), 3)) )

Xa_drop = chisq.test( colSums(drop_ch[,a]) ) # p<.001
Xb_drop = chisq.test( colSums(drop_ch[,b]) ) # p=.01
Xc_drop = chisq.test( colSums(drop_ch[,c]) ) # p=.056

target_ch = table(hum$StimSet, hum$DropLocation)

Xa_targ = chisq.test( colSums(target_ch[,a]) ) # n.s.
Xb_targ = chisq.test( colSums(target_ch[,b]) ) # n.s.
Xc_targ = chisq.test( colSums(target_ch[,c]) ) # n.s.

```

We first examine children's choice of drop objects and target objects to determine if children were choosing randomly, or had consistent preferences for some objects. We used a chi-square test of independence on children's choices (drop and target) from each set of objects (A, B, C).
Children's drop choices from set A significantly differed from chance `r report_chisq(Xa_drop)`.
Children's drop choices from set B also significantly differed from chance `r report_chisq(Xb_drop)`.
Children's drop choices from set C did not significantly differ from chance `r report_chisq(Xc_drop)`.
The 
Of all the drops, many
Children's target choices did not significantly differ from chance for set A `r report_chisq(Xa_targ)`, B `r report_chisq(Xb_targ)`, or C `r report_chisq(Xc_targ)`.

```{r table1-drop, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
get_table_string <- function(tableX, set) {
  tt = sort(colSums(tableX[,set]))
  tstr = paste(paste0(names(tt), " (", tt, "),"), collapse=' ')
  tstr = gsub('.{1}$', '', tstr)
  return(tstr)
}
dA = get_table_string(drop_ch, a)
dB = get_table_string(drop_ch, b)
dC = get_table_string(drop_ch, c)

tA = get_table_string(target_ch, a)
tB = get_table_string(target_ch, b)
tC = get_table_string(target_ch, c)

tabl <- tribble(~Set, ~`Drop Object (N)`, 
                "A", dA,
                "B", dB,
                "C", dC)
t1 <- xtable::xtable(tabl, caption="Children's drop object choices by set.")
#tab1 <- xtable::xtable(summary(out)$coef, digits=c(0, 2, 2, 1, 2), 
#                       caption = "This table prints across one column.")
print(t1, type="latex", comment = F, table.placement = "H")
```

```{r table2-target, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
tabl2 <- tribble(~Set, ~`Target Object (N)`, 
                "A", tA,
                "B", tB,
                "C", tC)
t2 <- xtable::xtable(tabl2, caption="Children's target object choices by set.")
#tab1 <- xtable::xtable(summary(out)$coef, digits=c(0, 2, 2, 1, 2), 
#                       caption = "This table prints across one column.")
print(t2, type="latex", comment = F, table.placement = "H")
```

```{r drop-choice, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.4, fig.height=2.5, set.cap.width=T, num.cols.cap=1, fig.cap = "Relative frequency of drop object choice as a function of stimulus set."}
ch_cond <- hum %>% 
  group_by(StimSet, DropChoice) %>%
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) 

ch_cond$StimSet <- factor(ch_cond$StimSet, levels = c("ba","ca","ab","cb","ac","bc"))
ggplot(ch_cond, aes(x=StimSet, y=freq, shape=DropChoice, color=DropChoice)) + # , size=n
  geom_point(alpha=.8) +
  scale_shape_manual(values=10:19) +
  #geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  xlab("Stimulus Set") + ylab("Rate of Drop Object Choice") + ylim(0,.66) + 
  langcog::scale_fill_solarized() + ggthemes::theme_few() + 
  geom_hline(yintercept=.33, lty='dashed')
```

```{r target-hit, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.4, fig.height=2.5, set.cap.width=T, num.cols.cap=1, fig.cap = "Relative frequency of targeted object as a function of stimulus set."}
hum$Target = hum$DropLocation
ch_cond <- hum %>% 
  filter(Target!="outside") %>%
  group_by(StimSet, Target) %>%
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) 

ch_cond$Target <- factor(ch_cond$Target, levels = c(shapes, "space"))
ggplot(ch_cond, aes(x=StimSet, y=freq, shape=Target, color=Target)) + # , size=n
  geom_point(alpha=.8) +
  scale_shape_manual(values=10:20) +
  #geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  xlab("Stimulus Set") + ylab("Rate of Target Object Choice") + ylim(0,.66) + 
  langcog::scale_fill_solarized() + ggthemes::theme_few() + 
  geom_hline(yintercept=.33, lty='dashed')
```

```{r target-space, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3.4, fig.height=2.5, set.cap.width=T, num.cols.cap=1, fig.cap = "Relative frequency of targeted object as a function of stimulus set."}

hum$TargetSpace = ifelse(hum$DropLocation=="space", hum$WhichSpace, hum$DropLocation)

ch_cond <- hum %>% 
  filter(is.element(TargetSpace, shapes)) %>%
  group_by(StimSet, TargetSpace) %>%
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) 

ch_cond$TargetSpace <- factor(ch_cond$TargetSpace, levels = shapes)
ggplot(ch_cond, aes(x=StimSet, y=freq, shape=TargetSpace, color=TargetSpace)) + # , size=n
  geom_point(alpha=.8) +
  scale_shape_manual(values=10:19) +
  #geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  xlab("Stimulus Set") + ylab("Rate of Target Location Choice") + ylim(0,.66) + 
  langcog::scale_fill_solarized() + ggthemes::theme_few() + 
  geom_hline(yintercept=.33, lty='dashed')
```


Figure 6 shows participants' mean proportion of unique objects dropped as a function of age.
Children of all ages sampled approximately equal proportions of the objects for dropping--roughly 70%, which is close to the 75% that would be expected if they were selected by chance (9 unique object occurring across 12 trials).

```{r unique-drop-objects, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=3, fig.height=2.5, set.cap.width=T, num.cols.cap=1, fig.cap = "Proportion of unique objects selected by participants. Error bars show boostrapped 95\\% confidence intervals."}
# 12 trials, 9 objects; random selection would be 9/12 = 75%...
uniq_s <- hum %>% group_by(SID, Age_Group) %>%
  summarise(DropObjs = n_distinct(DropChoice), N=n(), prop=DropObjs/N) 

uniq <- uniq_s %>% group_by(Age_Group) %>%
  tidyboot_mean(prop) 
  
ggplot(uniq, aes(x=Age_Group, y=mean)) + geom_point() +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  xlab("Age (years)") + ylab("Unique Objects Chosen") + ylim(0,1) + 
  langcog::scale_fill_solarized() + ggthemes::theme_few() +
  geom_hline(yintercept=.75, lty='dashed')
```

# Model

## Baseline Curiosity Policy

## Antagonistic Curiosity Policy

## Results


## Comparison with Children



# Discussion 



# Acknowledgements

This work was funded by HAI seed grant #. 
We thank X and Y for helpful comments.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
